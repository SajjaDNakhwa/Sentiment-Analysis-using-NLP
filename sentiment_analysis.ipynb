{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SajjaDNakhwa/Sentiment-Analysis-using-NLP/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis using Natural Language Processing\n"
      ],
      "metadata": {
        "id": "EZTbA6_9WEBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libaries"
      ],
      "metadata": {
        "id": "-ubjGXG2WVQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "McD7vOK4WYEr"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dataset\n"
      ],
      "metadata": {
        "id": "kqDZYhIzWhnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = pd.read_csv('Restaurant_Reviews.tsv', delimiter= '\\t', quoting = 3)\n",
        "print(ds.shape)"
      ],
      "metadata": {
        "id": "p7zoObSbWgoU",
        "outputId": "210e8fa6-ac97-4ce3-8d83-c7d0134d5718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Cleaning and Formatting"
      ],
      "metadata": {
        "id": "gZUoE0epWnX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "corpus = []"
      ],
      "metadata": {
        "id": "b3SENBkBWsOQ",
        "outputId": "d45cef76-62a1-4229-b222-dcba54617faa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to include important negative words such as 'no', 'not' etc. which are excluded by default\n",
        "# exclusion would hamper the analysis\n",
        "sw = stopwords.words('english')\n",
        "required_words = [\"no\", \"not\", \"don't\", \"isn't\", \"wasn't\", \"doesn't\", \"hasn't\", \"can\", \"cannot\", \"can't\"]\n",
        "for word in required_words:\n",
        "  if(word not in sw): continue\n",
        "  sw.remove(word)"
      ],
      "metadata": {
        "id": "GXHwLksDXlw0"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removes punctuations, lowers the case, stems the word to its root\n",
        "for i in range(0,1000):\n",
        "  review = re.sub('[^a-zA-Z]', ' ', ds['Review'][i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review = [ps.stem(word) for word in review if not word in set(sw)]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)\n",
        "# print(corpus)"
      ],
      "metadata": {
        "id": "uMmfPE7yYUvf"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the 'Bag Of Words'"
      ],
      "metadata": {
        "id": "LEGI3KsfZm1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sparse matrix of the bag of words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cvv = CountVectorizer(max_features=1500)\n",
        "X = cvv.fit_transform(corpus).toarray()\n",
        "y = ds.iloc[:, -1].values\n",
        "# print(X.shape)\n",
        "# print(y.shape)"
      ],
      "metadata": {
        "id": "6_wXEHuKZmMm"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting dataset into training and test sets"
      ],
      "metadata": {
        "id": "ZbnbUqrkZ6n2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "YwcLqDf-Z_73"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "mzj6FraDaMFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#after using several models, logistic regression gives the best accuracy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "5ZwDDCGmaNol",
        "outputId": "3f1d26cb-5ad8-47c2-a50a-772b2df23f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing and Validations"
      ],
      "metadata": {
        "id": "f7dCKV0-a_uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "id": "5eXDLksOa_EV",
        "outputId": "2edcbb13-d7eb-4cf5-e74c-09e12b0c66ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking accuracies"
      ],
      "metadata": {
        "id": "QauWZbNxbSx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "#confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "#accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "#precision value\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print(\"Precision:\", precision)\n",
        "#recall value\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print(\"Recall:\", recall)\n",
        "#f1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "id": "WfPO3pqabWqL",
        "outputId": "cf37c643-a887-47f3-cfae-a9da126b554d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[81 16]\n",
            " [26 77]]\n",
            "Accuracy: 0.79\n",
            "Precision: 0.8279569892473119\n",
            "Recall: 0.7475728155339806\n",
            "F1 Score: 0.7857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing using own reviews"
      ],
      "metadata": {
        "id": "cCcBNs3WdOqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_reviews = ['Fair food', 'The food can be much better.', 'The restaurant is nice, the waiter was very kind.', 'Horrible food, disgusting', 'Excellent environment and great food!! Would definitely recommend!']\n",
        "formatted_reviews = []\n",
        "for i in new_reviews:\n",
        "  review = re.sub('[^a-zA-Z]', ' ', i)\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review = [ps.stem(word) for word in review if not word in set(sw)]\n",
        "  review = ' '.join(review)\n",
        "  formatted_reviews.append(review)\n",
        "# print(formatted_reviews)"
      ],
      "metadata": {
        "id": "xd5K5FdYdTWM"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = classifier.predict(cvv.transform(formatted_reviews).toarray())\n",
        "for i in range(len(new_reviews)):\n",
        "  a = \"Positive Review\" if preds[i] == 1 else \"Negative Review\"\n",
        "  print(new_reviews[i], \":\", a)"
      ],
      "metadata": {
        "id": "uB8vpDf-el6f",
        "outputId": "f169f0f9-4170-41e3-eac4-835589dc14bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fair food : Negative Review\n",
            "The food can be much better. : Negative Review\n",
            "The restaurant is nice, the waiter was very kind. : Positive Review\n",
            "Horrible food, disgusting : Negative Review\n",
            "Excellent environment and great food!! Would definitely recommend! : Positive Review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Notes"
      ],
      "metadata": {
        "id": "D3H0m26gcxiL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Logistic Regression Model performs the best amongst classification models (Random Forest, Naive Bayes, SVM etc.).\n",
        "It gave an accuracy of around 79 which is fair.\n",
        "It still is not that good, I expect to improve it in the future. It performs well on obvious reviews where common words such as 'good', 'great', 'bad' etc. are used. A bigger dataset can help to improve it!"
      ],
      "metadata": {
        "id": "p2sZOGTsc3d-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}